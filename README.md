# Nuclear Energy Sentiment Analysis System

A sophisticated natural language processing system for analyzing nuclear energy-related content using advanced deep learning techniques and continuous learning.

## ğŸš€ Features

### Advanced Sentiment Analysis
- Custom BERT model fine-tuned for nuclear energy domain
- Multi-lingual support (EN, FR, DE, ES, IT)
- Aspect-based sentiment analysis:
  - Safety
  - Cost
  - Environmental impact
  - Technology
  - Policy
  - Public opinion

### Continuous Learning
- Automated model retraining
- Data quality validation
- Performance monitoring
- MLflow experiment tracking
- Model versioning

### Data Processing
- Multi-source content extraction
- Advanced text cleaning
- Parallel processing
- Efficient storage with Elasticsearch
- Redis caching for fast access

### Quality Monitoring
- Real-time metrics tracking
- Data drift detection
- Automated alerts
- Performance monitoring
- Prometheus/Grafana dashboards

### Performance Optimization
- Mixed precision training
- Batch processing
- Distributed computing
- Resource monitoring
- Caching strategies

## ğŸ“ Project Structure

```
nuclear-sentiment/
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ bloomberg_config.yaml   # Bloomberg API configuration
â”‚   â”œâ”€â”€ model_config.yaml       # Model parameters
â”‚   â”œâ”€â”€ monitoring_config.yaml  # Monitoring settings
â”‚   â””â”€â”€ system_config.yaml      # System-wide settings
â”‚
â”œâ”€â”€ data/                       # Data directory
â”‚   â”œâ”€â”€ raw/                   # Raw article data
â”‚   â”œâ”€â”€ processed/             # Processed articles
â”‚   â””â”€â”€ models/                # Trained model checkpoints
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ API.md                # API reference
â”‚   â”œâ”€â”€ BLOOMBERG.md          # Bloomberg integration guide
â”‚   â”œâ”€â”€ DATA_PROCESSING.md    # Data processing documentation
â”‚   â”œâ”€â”€ MODEL.md              # Model architecture details
â”‚   â”œâ”€â”€ MONITORING.md         # Monitoring system guide
â”‚   â””â”€â”€ CONFIGURATION.md      # Configuration guide
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ analysis/             # Analysis notebooks
â”‚   â”œâ”€â”€ experiments/          # Experiment notebooks
â”‚   â””â”€â”€ visualization/        # Visualization notebooks
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ data/                 # Data processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ processor.py      # Main data processor
â”‚   â”‚   â”œâ”€â”€ cleaner.py       # Text cleaning utilities
â”‚   â”‚   â””â”€â”€ loader.py        # Data loading utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ models/              # Model implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ nuclear_bert.py  # Nuclear BERT model
â”‚   â”‚   â””â”€â”€ embeddings.py    # Custom embeddings
â”‚   â”‚
â”‚   â”œâ”€â”€ training/            # Training pipelines
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ continuous_learning.py  # Continuous learning
â”‚   â”‚   â””â”€â”€ trainer.py      # Base trainer
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/         # Monitoring system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ quality_monitor.py  # Quality monitoring
â”‚   â”‚   â””â”€â”€ alerts.py      # Alert system
â”‚   â”‚
â”‚   â”œâ”€â”€ optimization/      # Performance optimization
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ performance.py # Performance utilities
â”‚   â”‚   â””â”€â”€ caching.py    # Caching system
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/     # Visualization tools
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dashboards.py # Grafana dashboards
â”‚   â”‚   â””â”€â”€ plots.py     # Plotting utilities
â”‚   â”‚
â”‚   â””â”€â”€ utils/            # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py    # Configuration utilities
â”‚       â”œâ”€â”€ logger.py    # Logging setup
â”‚       â””â”€â”€ metrics.py   # Evaluation metrics
â”‚
â”œâ”€â”€ tests/               # Test suite
â”‚   â”œâ”€â”€ data/           # Data processing tests
â”‚   â”œâ”€â”€ models/         # Model tests
â”‚   â”œâ”€â”€ training/       # Training tests
â”‚   â”œâ”€â”€ monitoring/     # Monitoring tests
â”‚   â””â”€â”€ optimization/   # Performance tests
â”‚
â”œâ”€â”€ docker/             # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile     # Main application
â”‚   â”œâ”€â”€ docker-compose.yml  # Service orchestration
â”‚   â””â”€â”€ prometheus/    # Prometheus configuration
â”‚
â”œâ”€â”€ scripts/           # Utility scripts
â”‚   â”œâ”€â”€ setup.sh      # Setup script
â”‚   â”œâ”€â”€ train.sh      # Training script
â”‚   â””â”€â”€ deploy.sh     # Deployment script
â”‚
â”œâ”€â”€ .env.example      # Example environment variables
â”œâ”€â”€ .gitignore       # Git ignore rules
â”œâ”€â”€ LICENSE         # License file
â”œâ”€â”€ README.md       # This file
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ setup.py       # Package setup file
```

## ğŸ›  Installation

### Prerequisites
- Python 3.9+
- Docker
- CUDA-capable GPU (recommended)

### Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/nuclear-sentiment
cd nuclear-sentiment
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Start required services:
```bash
# Start Elasticsearch
docker run -d -p 9200:9200 -e "discovery.type=single-node" elasticsearch:8.11.0

# Start Redis
docker run -d -p 6379:6379 redis:5.0.1

# Start MLflow
mlflow server --host 0.0.0.0 --port 5000

# Start Prometheus
prometheus --config.file=prometheus.yml
```

5. Configure environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

## ğŸ“Š Usage

### Basic Usage

```python
from src.models.nuclear_bert import NuclearBERTModel
from src.data.processor import DataProcessor

# Initialize model and processor
model = NuclearBERTModel()
processor = DataProcessor()

# Analyze sentiment
text = "Nuclear energy plays a crucial role in reducing carbon emissions."
result = model.predict(text)
print(f"Overall sentiment: {result.sentiment}")
print(f"Aspect sentiments: {result.aspects}")
```

### Continuous Learning

```python
from src.training.continuous_learning import ContinuousLearningPipeline

# Initialize pipeline
pipeline = ContinuousLearningPipeline()

# Start continuous learning
await pipeline.run()
```

### Monitoring

```python
from src.monitoring.quality_monitor import QualityMonitor

# Initialize monitor
monitor = QualityMonitor()

# Check data quality
metrics = await monitor.check_data_quality(data)
print(f"Quality metrics: {metrics}")
```

## ğŸ“ˆ Dashboards

### Grafana Dashboards
- Model Performance: `http://localhost:3000/d/model-performance`
- Data Quality: `http://localhost:3000/d/data-quality`
- System Metrics: `http://localhost:3000/d/system-metrics`

### MLflow UI
Access experiment tracking at `http://localhost:5000`

## ğŸ”§ Configuration

### Model Configuration
Edit `config/model_config.yaml` to configure:
- Model architecture
- Training parameters
- Inference settings

### System Configuration
Edit `config/system_config.yaml` to configure:
- Data processing
- Monitoring
- Alerts
- Performance optimization

## ğŸ“ Documentation

Detailed documentation is available in the `docs` directory:
- [API Reference](docs/API.md)
- [Model Architecture](docs/MODEL.md)
- [Data Processing](docs/DATA_PROCESSING.md)
- [Monitoring](docs/MONITORING.md)
- [Configuration Guide](docs/CONFIGURATION.md)

## ğŸ§ª Testing

Run tests:
```bash
# Run all tests
pytest

# Run specific test suite
pytest tests/models/test_nuclear_bert.py
```

## ğŸ“Š Performance

### Hardware Requirements
- Minimum: 16GB RAM, 4 CPU cores
- Recommended: 32GB RAM, 8 CPU cores, NVIDIA GPU with 8GB+ VRAM

### Benchmarks
- Processing Speed: ~1000 articles/minute
- Model Inference: ~100ms/article
- Training: ~2 hours/epoch on recommended hardware

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Bloomberg API for data access
- Hugging Face for transformer models
- ElasticSearch for efficient storage
- Redis for caching
- Prometheus/Grafana for monitoring
