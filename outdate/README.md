# Nuclear Energy Sentiment Analysis System

A sophisticated natural language processing system for analyzing nuclear energy-related content using advanced deep learning techniques and continuous learning.

## Overview
A comprehensive Natural Language Processing (NLP) pipeline for analyzing nuclear energy news articles from Bloomberg and IAEA sources. The project includes data collection, preprocessing, analysis, and visualization components.

## ğŸš€ Features

### Advanced Sentiment Analysis
- Custom BERT model fine-tuned for nuclear energy domain
- Multi-lingual support (EN, FR, DE, ES, IT)
- Aspect-based sentiment analysis:
  - Safety
  - Cost
  - Environmental impact
  - Technology
  - Policy
  - Public opinion

### Continuous Learning
- Automated model retraining
- Data quality validation
- Performance monitoring
- MLflow experiment tracking
- Model versioning

### Data Processing
- Multi-source content extraction
- Advanced text cleaning
- Parallel processing
- Efficient storage with Elasticsearch
- Redis caching for fast access

### Quality Monitoring
- Real-time metrics tracking
- Data drift detection
- Automated alerts
- Performance monitoring
- Prometheus/Grafana dashboards

### Performance Optimization
- Mixed precision training
- Batch processing
- Distributed computing
- Resource monitoring
- Caching strategies

## ğŸ“ Project Structure

```
NLP/
â”œâ”€â”€ cache/                    # Cache directory
â”‚   â”œâ”€â”€ bloomberg/           # Bloomberg API cache
â”‚   â””â”€â”€ models/              # Model cache
â”‚
â”œâ”€â”€ config/                   # Configuration files
â”‚   â”œâ”€â”€ bloomberg_config.yaml # Bloomberg API configuration
â”‚   â”œâ”€â”€ config.yaml          # Main configuration
â”‚   â”œâ”€â”€ country_coordinates.json  # Geographical data
â”‚   â”œâ”€â”€ italian_financial_terms.yml  # Financial terms
â”‚   â”œâ”€â”€ report_periods.yml   # Reporting periods
â”‚   â””â”€â”€ requirements.txt     # Config-specific requirements
â”‚
â”œâ”€â”€ data/                    # Data directory
â”‚   â”œâ”€â”€ processed/          # Processed data
â”‚   â””â”€â”€ raw/               # Raw data
â”‚
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ API.md             # API reference
â”‚   â”œâ”€â”€ BLOOMBERG.md       # Bloomberg integration guide
â”‚   â”œâ”€â”€ CONTRIBUTING.md    # Contributing guidelines
â”‚   â”œâ”€â”€ architecture.md    # System architecture
â”‚   â”œâ”€â”€ changelog.md       # Version history
â”‚   â”œâ”€â”€ requirements.md    # Requirements documentation
â”‚   â””â”€â”€ user_guide.md     # User guide
â”‚
â”œâ”€â”€ logs/                  # Log files
â”‚
â”œâ”€â”€ output/               # Output directory
â”‚   â”œâ”€â”€ figures/         # Generated figures
â”‚   â””â”€â”€ reports/        # Generated reports
â”‚
â”œâ”€â”€ scripts/             # Utility scripts
â”‚   â”œâ”€â”€ run_pipeline.sh # Pipeline execution
â”‚   â””â”€â”€ setup_env.sh   # Environment setup
â”‚
â”œâ”€â”€ src/                # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py        # Main application entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/      # Analysis modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_analyzer.py
â”‚   â”‚   â”œâ”€â”€ geo_analysis.py
â”‚   â”‚   â”œâ”€â”€ geopolitical_context.py
â”‚   â”‚   â”œâ”€â”€ keyword_extraction.py
â”‚   â”‚   â”œâ”€â”€ semantic_analysis.py
â”‚   â”‚   â”œâ”€â”€ sentiment_analysis.py
â”‚   â”‚   â”œâ”€â”€ temporal_analysis.py
â”‚   â”‚   â””â”€â”€ topic_modeling.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/          # Data processing
â”‚   â”‚   â””â”€â”€ processor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_ingestion/  # Data ingestion
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bloomberg_client.py
â”‚   â”‚   â”œâ”€â”€ html_parser.py
â”‚   â”‚   â”œâ”€â”€ ingestion.py
â”‚   â”‚   â””â”€â”€ pdf_parser.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/        # Model implementations
â”‚   â”‚   â””â”€â”€ nuclear_bert.py
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/    # Monitoring system
â”‚   â”‚   â””â”€â”€ quality_monitor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ optimization/  # Performance optimization
â”‚   â”‚   â””â”€â”€ performance.py
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/  # Text preprocessing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ text_cleaner.py
â”‚   â”‚
â”‚   â”œâ”€â”€ training/      # Training pipelines
â”‚   â”‚   â””â”€â”€ continuous_learning.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/         # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”‚
â”‚   â””â”€â”€ visualization/  # Visualization tools
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ dashboard.py
â”‚       â””â”€â”€ report_generator.py
â”‚
â”œâ”€â”€ templates/          # Report templates
â”‚   â”œâ”€â”€ report_template.html
â”‚   â””â”€â”€ report_template.md
â”‚
â”œâ”€â”€ tests/             # Test suite
â”‚   â””â”€â”€ data_ingestion/
â”‚       â””â”€â”€ test_bloomberg_client.py
â”‚
â”œâ”€â”€ .env.example       # Example environment variables
â”œâ”€â”€ README.md         # This file
â””â”€â”€ requirements.txt  # Python dependencies
```

## ğŸ›  Installation

### Prerequisites
- Python 3.9+
- Docker
- CUDA-capable GPU (recommended)

### Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/nuclear-sentiment
cd nuclear-sentiment
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Start required services:
```bash
# Start Elasticsearch
docker run -d -p 9200:9200 -e "discovery.type=single-node" elasticsearch:8.11.0

# Start Redis
docker run -d -p 6379:6379 redis:5.0.1

# Start MLflow
mlflow server --host 0.0.0.0 --port 5000

# Start Prometheus
prometheus --config.file=prometheus.yml
```

5. Configure environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

## ğŸ“Š Usage

### Basic Usage

```python
from src.models.nuclear_bert import NuclearBERTModel
from src.data.processor import DataProcessor

# Initialize model and processor
model = NuclearBERTModel()
processor = DataProcessor()

# Analyze sentiment
text = "Nuclear energy plays a crucial role in reducing carbon emissions."
result = model.predict(text)
print(f"Overall sentiment: {result.sentiment}")
print(f"Aspect sentiments: {result.aspects}")
```

### Continuous Learning

```python
from src.training.continuous_learning import ContinuousLearningPipeline

# Initialize pipeline
pipeline = ContinuousLearningPipeline()

# Start continuous learning
await pipeline.run()
```

### Monitoring

```python
from src.monitoring.quality_monitor import QualityMonitor

# Initialize monitor
monitor = QualityMonitor()

# Check data quality
metrics = await monitor.check_data_quality(data)
print(f"Quality metrics: {metrics}")
```

## ğŸ“ˆ Dashboards

### Grafana Dashboards
- Model Performance: `http://localhost:3000/d/model-performance`
- Data Quality: `http://localhost:3000/d/data-quality`
- System Metrics: `http://localhost:3000/d/system-metrics`

### MLflow UI
Access experiment tracking at `http://localhost:5000`

## ğŸ”§ Configuration

### Model Configuration
Edit `config/model_config.yaml` to configure:
- Model architecture
- Training parameters
- Inference settings

### System Configuration
Edit `config/system_config.yaml` to configure:
- Data processing
- Monitoring
- Alerts
- Performance optimization

## ğŸ“ Documentation

Detailed documentation is available in the `docs` directory:
- [API Reference](docs/API.md)
- [Model Architecture](docs/MODEL.md)
- [Data Processing](docs/DATA_PROCESSING.md)
- [Monitoring](docs/MONITORING.md)
- [Configuration Guide](docs/CONFIGURATION.md)

## ğŸ§ª Testing

Run tests:
```bash
# Run all tests
pytest

# Run specific test suite
pytest tests/models/test_nuclear_bert.py
```

## ğŸ“Š Performance

### Hardware Requirements
- Minimum: 16GB RAM, 4 CPU cores
- Recommended: 32GB RAM, 8 CPU cores, NVIDIA GPU with 8GB+ VRAM

### Benchmarks
- Processing Speed: ~1000 articles/minute
- Model Inference: ~100ms/article
- Training: ~2 hours/epoch on recommended hardware

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Bloomberg API for data access
- Hugging Face for transformer models
- ElasticSearch for efficient storage
- Redis for caching
- Prometheus/Grafana for monitoring

## Future Enhancements
1. Real-time analysis capabilities
2. Advanced ML model integration
3. Interactive web dashboard
4. Multi-language support
5. API integration